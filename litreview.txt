SUMMARY OF PAPERS RELATED TO YELP DATA

1. A Social Network-Based Recommender System (SNRS)
Authors: Jianming He, Wesley W. Chu
Link: http://link.springer.com/chapter/10.1007%2F978-1-4419-6287-4_4

The authors propose an alternative to collaborative filtering called “social network-based recommender system” (SNRS). 
In order to predict a user U’s rating for an item I, the system incorporates:
	-U’s preference for items similar to I: P(U’s rating = k|item with same attributes as I)
	-General acceptance of the target item I: P(rating = k|user with same attributes as U)
	-Ratings of U’s immediate friends: P(U’s rating = k|ratings of I from U’s immediate friends)
		> The way the authors propose doing this is using a “histogram” of rating differences to measure 
		correlation between two users (see page 56)
(For exact equation, see eq 4.3 on page 53)
As an extension the authors also put forward an “iterative classification” method that incorporates the ratings of friends of friends (details/pseudocode on page 58).

The dataset used to evaluate SNRS was from Yelp (specifically restaurant reviews). The authors specify that in general, 18.6% of the restaurants reviewed by a user were also reviewed by at least one of his/her friends (more than chance). They also found that if two reviewers are immediate friends, their reviews differ by 0.88 on average (std dev 0.89) versus 1.05 for non-friends (std dec 0.98). The authors evaluated their recommendations against multiple other systems including collaborative filtering, naive bases, using the average rating of immediate friends, and using the ratings of friends weighted by cosine similarity to the friend. SNRS was found to have the lowest mean average error (MAE), while collaborative filtering was found to have the highest. The coverage (percent of testing instances for which a method can make predictions) of all methods was relatively low, but collaborative filtering had the highest coverage, followed by SNRS with friends of friends (makes sense because CF does not require that the user have 3 friends/friends of friends who have rated the same restaurant). Collaborative filtering is also more negatively affected by data sparsity. SNRS is has lower MAE when the system does not take into consideration friends of friends (0.716 without versus 0.682 with). However, adding friends of friends doubles coverage suggesting that is still worthwhile. 

The authors suggest several future directions, the most detailed of which is semantic filtering (ex: filtering to look at reviews from similar users that are focused on food to predict a rating specifically for food, looking at semantics in friends relationships, etc.). This was found to be helpful when evaluated on a dataset of 22 students who were asked to rate articles based on 3 factors and to specify which of the other students they agreed/disagreed with on average for each of these 3 factors. Other suggestions include taking into consideration “network value”/influence, trust, and “adoption values.”

2. Matrix Factorization Techniques for Recommender Systems
Authors: Yehuda Koren, Robert Bell, Chris Volinsky
Link: https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf

NOTE: This seems to be the paper that last year’s group based their model off of. Makes sense: seems like it’s the state of the art and is written by the winners of the Netflix challenge. 

This paper focuses on latent factor models for collaborative filtering. Latent factor models characterize items and users based on ~20-100 factors. For items, each factor measures something like comedy versus drama, depth of character development, etc. For users, each factor measures how much a user tends to like movies with high scores on the corresponding movie factor. The model presented is based on matrix factorization. The factors are stored in vectors q_{i} (for the item) and p_{u} for the user. The most basic prediction of user u’s rating of item i (r_{ui}) is the dot product of the item and user vectors (q_{i}^{T}p_{u}).

In order to compute the mapping from item/user to vectors q_{i}/p_{u}, the system minimizes the regularized square error (eq 2 on page 44). There are two ways to perform the minimization: stochastic gradient descent and alternating least squares. Alternating least squares rotates between fixing the q_{i}’s and fixing the p_{u}’s in order to make the optimization problem quadratic/convex; this method is suitable in situations where the system can use parallelization to speed it up and in cases where looping over every single training case (as is done in gradient descent) is not tractable. Generally, gradient descent is faster and easier though.

To improve the model, we can add intercepts of the form b_{ui} = m + b_{i} + b_{u}, where m is the overall average rating, b_{u} is the deviation of user u and b_{i} is the derivation of user i (e.g. if the overall average rating is 3.7, Titanic is rated 0.5 starts above the average, and Joe is critical user who rates 0.3 starts lower than the bias term would be 3.7-0.5-0.3). 

The authors also describe how additional input sources may be added to the model in order to help with the cold-start problem. They specifically describe how to enhance the user representation by adding additional sums of vectors that can represent demographic information or implicit preference to p_{u} (eq 6 on page 46). Using this same method, we could add information about a user’s social network or information about the semantics of a given user’s review text.

The authors also discuss incorporating temporal dynamics by decomposing ratings into distinct terms. You can have item biases (b_{i}), user biases (b_{u}), and user preferences (p_{u}) as functions of time, which allows the model to capture how, say, the popularity of a movie changes over time.

In systems centered around implicit feedback, the authors also explain the possibility of including a confidence level, allowing the model to give less weight to less meaningful observations (eq 8 on page 47).  


3.



 